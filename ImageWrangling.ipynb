{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageWrangling (4).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZK4SI9igWMa",
        "colab_type": "code",
        "outputId": "1fbcfcac-24b3-4f6f-cd69-c45bd40e01d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Cell #1\n",
        "# The first cell (run Cell #1) loads in a few data sets of interest, including: T1, T2, GAD on several subjects with brain tumors. \n",
        "# these are DICOM images, so we have to first convert them to nifti\n",
        "# and the nifti converter leaves the output in the source folder, so we have\n",
        "# to move them and also rename them. Will use python for that\n",
        "\n",
        "!rm -rf MC-ImageWrangling\n",
        "!git clone https://github.com/slowvak/MC-ImageWrangling.git\n",
        "  \n",
        "!unzip -q MC-ImageWrangling/Bet-n-dcm2nii.zip\n",
        "!rm -rf images\n",
        "\n",
        "!mkdir images\n",
        "!cd images; unzip -q \"../MC-ImageWrangling/S1-4.zip\" \n",
        "!cd images; unzip -q \"../MC-ImageWrangling/S5-8.zip\" \n",
        "!cd images; unzip -q \"../MC-ImageWrangling/S9-12.zip\" \n",
        "!cd images; unzip -q \"../MC-ImageWrangling/S13-16.zip\" \n",
        "\n",
        "!rm -rf nii\n",
        "!rm -rf tmp\n",
        "\n",
        "!mkdir tmp\n",
        "!mkdir nii\n",
        "\n",
        "NIFTI_PATH = './nii'\n",
        "# now some python code to loop over all the folders and convert from DICOM to nifti\n",
        "# and then since the command doesn't allow speciyfing the name, will also move\n",
        "#them from temp directory to an organized directory.\n",
        "# this is why seemingly simple tasks always take longer than planned...\n",
        "\n",
        "import os, fnmatch\n",
        "\n",
        "for subj in fnmatch.filter(os.listdir('./images'), 'S*'):\n",
        "    subj_path = os.path.join('./images', subj)\n",
        "    series = os.listdir(subj_path)\n",
        "    series = ['T1', 'T2', 'GAD']\n",
        "    for ser in series:\n",
        "        dcm_path = os.path.join (subj_path, ser)\n",
        "        cmd = \"./dcm2nii -o tmp %s\" % (dcm_path)\n",
        "        os.system(cmd)\n",
        "#        print (cmd)\n",
        "        # now have to find tehe .nii.gz and move it out\n",
        "        f = fnmatch.filter(os.listdir('./tmp'), '*.nii.gz')\n",
        "        out_dir = os.path.join (NIFTI_PATH, subj)\n",
        "        if not os.path.exists(out_dir):\n",
        "            os.mkdir(out_dir)\n",
        "        out_path = os.path.join (out_dir, ser)\n",
        "        cmd = \"mv ./tmp/%s %s.nii.gz\" % (f[0], out_path)\n",
        "        os.system(cmd)\n",
        "#        print (cmd)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MC-ImageWrangling'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 67 (delta 23), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWSW7VUOhpK9",
        "colab_type": "code",
        "outputId": "6f3ae7bc-429c-41fd-e431-372d8c367e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# CELL #2\n",
        "# Now do some basic processing to prepare the images\n",
        "# Note this will take about 30 minutes to complete.\n",
        "# If you want to skip it, the output is already computed and saved for next cell\n",
        "#!ls ./nii\n",
        "#!ls ./nii/S1\n",
        "\n",
        "# FSL (flirt-the image registration application) complains if this environment variable is not set\n",
        "os.environ['FSLOUTPUTTYPE'] = 'NIFTI_GZ'\n",
        "\n",
        "#for subj in ['S1','S2']:\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    print (\"Working on \" + subj_path)\n",
        "    series = fnmatch.filter(os.listdir(subj_path), '*.nii.gz')\n",
        "    for ser in ['T1', 'T2', 'GAD']:\n",
        "        nii_file = os.path.join (subj_path, ser)\n",
        "# First, perform N4 bias correction. Not required, but may improve results. Also must track new names\n",
        "        new_file = os.path.join (subj_path, 'N4-' + ser)\n",
        "        cmd = \"./N4BiasFieldCorrection -i %s.nii.gz -o %s.nii.gz\" % (nii_file, new_file)\n",
        "        os.system(cmd)\n",
        "#        print (cmd)\n",
        "# Next, Register the images to the post-Gad images so skip the GAD\n",
        "    GAD_file = os.path.join (subj_path, 'N4-GAD.nii.gz')\n",
        "    T1_file =  os.path.join (subj_path, 'N4-T1.nii.gz')\n",
        "    new_file = os.path.join (subj_path, 'Reg-T1.nii.gz')\n",
        "    cmd = \"./flirt -in %s -ref %s  -out %s\" % (T1_file, GAD_file, new_file)\n",
        "    os.system(cmd)\n",
        "#    print (cmd)\n",
        "    T2_file =  os.path.join (subj_path, 'N4-T2.nii.gz')\n",
        "    new_file = os.path.join (subj_path, 'Reg-T2.nii.gz')\n",
        "    cmd = \"./flirt -in %s -ref %s  -out %s\" % (T2_file, GAD_file, new_file)\n",
        "    os.system(cmd)\n",
        "#    print (cmd)\n",
        "# can also try to mask out non-brain tissue, but that doesn't work as well on thick slice MRI\n",
        "# first, compute the mask. \n",
        "#    cmd = \"./bet2 %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T1'), os.path.join (subj_path, 'mask'))\n",
        "#    os.system(cmd)\n",
        "#    cmd = \"./fslmaths %s.nii.gz -mas %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T1'), os.path.join (subj_path, 'mask'), os.path.join (subj_path, 'Reg-T1'))\n",
        "#    os.system(cmd)\n",
        "#    cmd = \"./fslmaths %s.nii.gz -mas %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T2'), os.path.join (subj_path, 'mask'), os.path.join (subj_path, 'Reg-T2'))\n",
        "#    os.system(cmd)\n",
        "#    cmd = \"./fslmaths %s.nii.gz -mas %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'N4-GAD'), os.path.join (subj_path, 'mask'), os.path.join (subj_path, 'N4-GAD'))\n",
        "\n",
        "# finally, copy over original so you can skip these steps if you like\n",
        "    cmd = \"cp %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T1'), os.path.join (subj_path, 'T1'))\n",
        "    os.system(cmd)\n",
        "    cmd = \"cp %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'Reg-T2'), os.path.join (subj_path, 'T2'))\n",
        "    os.system(cmd)\n",
        "    cmd = \"cp %s.nii.gz %s.nii.gz\" % (os.path.join (subj_path, 'N4-GAD'), os.path.join (subj_path, 'GAD'))\n",
        "    os.system(cmd) \n",
        "\n",
        "#!ls -l ./nii/S1        \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on ./nii/S7\n",
            "Working on ./nii/S9\n",
            "Working on ./nii/S1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2GKn6tTy91n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell #3\n",
        "\n",
        "# This unzips known good files processed as above.\n",
        "# skip this cell if you want to use your version\n",
        "\n",
        "for subj in ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16']:\n",
        "    cmd = 'cd ./nii; unzip -q ../MC-ImageWrangling/%s.zip .' % (subj)\n",
        "    os.system(cmd)\n",
        "# must also delete the DICOM and intermediate files to have enough space to make the new files\n",
        "!rm -rf nii/Reg*\n",
        "!rm -rf nii/N4-*\n",
        "!rm -rf ./images\n",
        "\n",
        "\n",
        "\n",
        "# At this point, we have nifti files (T1.nii.gz, T2.nii.gz, GAD.nii.gz) for each subject\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emAoMBNF8yPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell #4\n",
        "\n",
        "# There is also a text file called 'TumorSlices.csv' that I created which has subject ID, \n",
        "# first slice with contrast enhancement and last slice with contrast enhancement.\n",
        "# note that subjects 2 and 14 don't have much enhancement\n",
        "# we will read this into a Pandas dataframe\n",
        "# Pandas is very popular for data analysis, and has a built-in function to read CSV (and excel) files\n",
        "import pandas as pd\n",
        "df = pd.read_csv ('./MC-ImageWrangling/TumorSlices.csv')\n",
        "print (df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prfwTHAoUSxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell #5\n",
        "# create new versions of the T1, GAD, and T2 images that range from 0 to 255, and where the 0 intensity value maps to the 5th percentile value \n",
        "# and 255 maps to the 95th percentile value.\n",
        "import imageio\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "MIN_MR = 20\n",
        "\n",
        "def rescale_5_95_percentile(image):\n",
        "    dims = np.shape(image)\n",
        "    image_1d = image.reshape(1, image.size)\n",
        "    above = np.where(image_1d>MIN_MR, image_1d, image_1d)\n",
        "    if above.size < image_1d.size/2:\n",
        "        above = image_1d # avoid bad MIN_MR thresholds\n",
        "    sorted_im = np.sort(above, axis = None)\n",
        "    \n",
        "    start = int(sorted_im.size / 20)  # 20 = 5%\n",
        "    end = int(sorted_im.size * 19 / 20) # 95%\n",
        "    start_val = sorted_im[start]\n",
        "    end_val = sorted_im[end]\n",
        "    \n",
        "    image = np.maximum(image, start_val) # map values below the end_val to end_val\n",
        "    image = np.minimum(image, end_val)   # map values above the end_val to end_val\n",
        "    image = image - start_val # subtract the starting intensity\n",
        "\n",
        " #   print (\"rescaling range \" + str(newmin) + \" to \" + str(histo[1][index]))\n",
        "    image = (np.maximum(image, 0) / image.max()) * 255.0\n",
        "    return image\n",
        "\n",
        "def nifti_to_img(red_file, green_file, blue_file, not_dir, yes_dir, startSlice, endSlice, subject):\n",
        "### red_ green_ and blue_files are the nifit files that will be combined to go into the PNG\n",
        "### not_dir is the direcotry where PNGs are stored if they are not in the (inclusive)\n",
        "### range set by startSlice/endSlice\n",
        "### yes_dir is where they are stored when they ARE in the range\n",
        "### subject is the ID so that we can track where images came from\n",
        "\n",
        "    try:\n",
        "        nifti = nib.load(red_file)\n",
        "        nif_header = nifti.header\n",
        "        red_image = nifti.get_fdata()\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "    try:\n",
        "        if os.path.isfile(green_file):\n",
        "            nifti = nib.load(green_file)\n",
        "            nif_header = nifti.header\n",
        "            green_image = nifti.get_fdata()\n",
        "        else:\n",
        "            pass\n",
        "    except:  # if can't load, then use red image\n",
        "        green_image = red_image\n",
        "    \n",
        "    try:\n",
        "        if os.path.isfile(blue_file):\n",
        "            nifti = nib.load(blue_file)\n",
        "\n",
        "            nif_header = nifti.header\n",
        "            blue_image = nifti.get_fdata()\n",
        "        else:\n",
        "            pass\n",
        "    except:  # if can't load, then use red image\n",
        "        blue_image = red_image\n",
        "        \n",
        "# now scale the intensity for each image        \n",
        "    red_image = rescale_5_95_percentile(red_image)\n",
        "    green_image = rescale_5_95_percentile(green_image)\n",
        "    blue_image = rescale_5_95_percentile(blue_image)\n",
        "# then convert to 8 bits\n",
        "    red_image = red_image.astype(np.uint8)     \n",
        "    green_image = green_image.astype(np.uint8)     \n",
        "    blue_image = blue_image.astype(np.uint8)   \n",
        "    \n",
        "# get the number of slices\n",
        "    dims = np.shape(red_image)\n",
        "    zd = dims[2]\n",
        "\n",
        "    for z in range(0, zd):\n",
        "        outname = subject + \"-{0:04d}\".format(z) + '.png'\n",
        "        if z >= startSlice and z <= endSlice:  # this is enhancing\n",
        "            out_dir = yes_dir\n",
        "        else:\n",
        "            out_dir = not_dir\n",
        "        outname = os.path.join(out_dir, outname)\n",
        "        if not os.path.exists(out_dir):\n",
        "            os.makedirs(out_dir)\n",
        "        combined = np.dstack((red_image[:,:,z],green_image[:,:,z],\n",
        "                              blue_image[:,:,z]))\n",
        "## . images come in rotated\n",
        "        combined = np.rot90(combined, k=1)\n",
        "#        print ('Name: ' + outname)\n",
        "        imageio.imwrite(outname, combined)\n",
        "    return zd\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EuA77JqUbfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell #6\n",
        "# take the GAD nii, scale it to 0-255 and store that into the red channel\n",
        "# same for T1 (green) and T2 (blue)\n",
        "# PNG files are stored in enh / nonenh folders based on the csv file\n",
        "\n",
        "# store the png files into enhancing or nonenhancing folders after making sure they are cleared\n",
        "\n",
        "!rm -rf classified\n",
        "\n",
        "!mkdir classified\n",
        "\n",
        "for subj in os.listdir(NIFTI_PATH):\n",
        "    subj_path = os.path.join(NIFTI_PATH, subj)\n",
        "    red_f = os.path.join(subj_path, 'GAD.nii.gz')\n",
        "    green_f = os.path.join(subj_path, 'T1.nii.gz')\n",
        "    blue_f = os.path.join(subj_path, 'T2.nii.gz')\n",
        "    startSlice = df.loc[df.Subject == subj, 'StartSlice'].values[0]\n",
        "    endSlice = df.loc[df.Subject == subj, 'EndSlice'].values[0]\n",
        "    print (\"Making PNG file for \" + subj + \" start: \" + str(startSlice) + \" end: \" + str(endSlice))\n",
        "    count = nifti_to_img(red_f, green_f, blue_f, './classified/not', './classified/enh', startSlice, endSlice, subj)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyo41ZFIUsjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell #7\n",
        "# display some images to see the result\n",
        "# expand the left column if it isnt (fig 1)\n",
        "# open teh enhancing or nonenhancing folders and you should see many files with\n",
        "# format Snn-000m.png where n is the subject number and m is the slice number\n",
        "# the image will then appear on the right\n",
        "# enhancing is red, T2 bright is blue, if all are bright it is white\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MeAVs12qLNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cell #8\n",
        "# now we are ready to load data and train classifier\n",
        "# while we did this in separate cells before, we will do it all in one\n",
        "# this should look familiar.\n",
        "!pip3 install fastai\n",
        "from fastai.vision import *\n",
        "\n",
        "classes_dir = \"./classified\"\n",
        "\n",
        "np.random.seed(42)\n",
        "data = ImageDataBunch.from_folder(classes_dir, train=\".\", valid_pct=0.2,\n",
        "        ds_tfms=get_transforms(), size=64, num_workers=4).normalize(imagenet_stats)\n",
        "data.classes\n",
        "data.classes, data.c, len(data.train_ds), len(data.valid_ds)\n",
        "\n",
        "learn = cnn_learner(data, models.resnet34, metrics=error_rate)\n",
        "\n",
        "learn.fit_one_cycle(50)\n",
        "\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()\n",
        "# not great performance. \n",
        "# look at some errors--why is it failing? \n",
        "interp.plot_top_losses(9, figsize=(10,10))\n",
        "doc(interp.plot_top_losses)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}